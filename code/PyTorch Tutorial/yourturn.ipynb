{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d5516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3af950",
   "metadata": {},
   "source": [
    "# Your Turn!\n",
    "Ok now that you are familiar with the synatx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db2eb8",
   "metadata": {},
   "source": [
    "# Data\n",
    "We are using FashionMNIST data. The features (inputs) are black & white photos of clothes. The labels (outputs) are which type of clothing it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "def filter_classes(dataset, classes):\n",
    "    \"\"\"\n",
    "    Filter dataset to only include specified classes.\n",
    "    Relabels classes to 0, 1, 2, ... for the subset.\n",
    "    \"\"\"\n",
    "    # Map old labels to new labels: {0: 0, 3: 1, 6: 2} for CLASSES=[0,3,6]\n",
    "    label_map = {old: new for new, old in enumerate(classes)}\n",
    "    \n",
    "    # Find indices where label is in our class list\n",
    "    mask = torch.tensor([label in classes for label in dataset.targets])\n",
    "    indices = mask.nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    # Create filtered dataset\n",
    "    dataset.data = dataset.data[indices]\n",
    "    dataset.targets = torch.tensor([label_map[t.item()] for t in dataset.targets[indices]])\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "CLASSES = list(range(10))\n",
    "train_dataset = filter_classes(train_dataset, CLASSES)\n",
    "test_dataset = filter_classes(test_dataset, CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97d43abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x140593f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIDBJREFUeJzt3Xts1fX9x/HXobSHIuUog97WUouCGsuYXOQyVCDS2Ey8oAvqYiCZRiewkOLMGEtstoQaDIQ/2FjmFoRNlCxBdIOI3bBFxzCVoTA0DkaROnrSgdBTCrS0/f7+IPS3Um6fj+f03dM+H8lJ6DnnxffTb7/tq9+ec94nFARBIAAADPSzXgAAoO+ihAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCmv/UCLtbe3q6jR48qIyNDoVDIejkAAEdBEKixsVG5ubnq1+/K5zo9roSOHj2q/Px862UAAL6m2tpa5eXlXfE+Pa6EMjIyrJcAJNzNN9/snLn33nudMydOnHDOSFJzc7Nz5sMPP3TO1NXVOWeQPK7l53nCSuhXv/qVXn75ZdXV1en222/XqlWrdNddd101x5/g0BekpKQ4Z8LhsHMmLS3NOSOd/7O4q6v92QWX5/NzLxnGfl7L55WQo2bjxo1atGiRli5dqj179uiuu+5SSUmJjhw5kojNAQCSVEJKaOXKlfrBD36gp556SrfddptWrVql/Px8rVmzJhGbAwAkqbiXUEtLi3bv3q3i4uJO1xcXF2vnzp1d7t/c3KxYLNbpAgDoG+JeQseOHVNbW5uysrI6XZ+VlaVoNNrl/uXl5YpEIh0XnhkHAH1Hwh5JvPgBqSAILvkg1ZIlS9TQ0NBxqa2tTdSSAAA9TNyfHTd06FClpKR0Oeupr6/vcnYknX/Gj8+zfgAAyS/uZ0JpaWkaN26cKioqOl1fUVGhKVOmxHtzAIAklpDXCZWWlurJJ5/U+PHjNXnyZP3mN7/RkSNH9OyzzyZicwCAJJWQEpozZ46OHz+un//856qrq1NRUZG2bt2qgoKCRGwOAJCkQkEPe9ltLBZTJBKxXgaSnO/kje76dti+fbtzZsKECc6Z1NRU54zkN53Bx29/+1vnzJgxY5wz6enpzhlJev/9950zixcvds6cOXPGOeMzdUOS2travHI+GhoaNHjw4CvehzkbAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzCRkijZgracPML3UGzxezcmTJ50zaWlpzhlJamlpcc5cf/31zpnvf//7zhmfYaTnzp1zzkhSUVGRc6a1tdU586Mf/cg54/u19RmWmkicCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzDBFG71Sv35+v1+1t7c7Z3ymGQ8fPtw5c/r0aedMSkqKc0bym4jd1NTknPnqq6+cMyNGjHDO+EwFl/ymsa9cudJrW658jtWeiDMhAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZhhgih7PZ4ik7wBTHzNmzHDODBo0yDlz6tQp54zPcFVfqampzhmf/RAOh50z/fv7/ajbt2+fc8bnc8rOznbORKNR54zk972RyGGpnAkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwwwBT9HhBEDhnWlpaErCSS5swYYJzxmf45MmTJ50zo0aNcs5Ifvv8zJkzzpmhQ4c6Z3zW1tjY6JyRpLfeess5M3PmTOfMP/7xD+eM7wBTn4HAicSZEADADCUEADAT9xIqKytTKBTqdPF5rwwAQO+XkMeEbr/9dv3lL3/p+DglJSURmwEAJLmElFD//v05+wEAXFVCHhM6cOCAcnNzVVhYqMcee0yHDh267H2bm5sVi8U6XQAAfUPcS2jixIlav369tm3bpldeeUXRaFRTpkzR8ePHL3n/8vJyRSKRjkt+fn68lwQA6KHiXkIlJSV65JFHNHr0aN17773asmWLJGndunWXvP+SJUvU0NDQcamtrY33kgAAPVTCX6x63XXXafTo0Tpw4MAlbw+HwwqHw4leBgCgB0r464Sam5v12WefKScnJ9GbAgAkmbiX0PPPP6+qqirV1NToww8/1KOPPqpYLKa5c+fGe1MAgCQX9z/Hffnll3r88cd17NgxDRs2TJMmTdKuXbtUUFAQ700BAJJc3EvojTfeiPd/iT7OZ+Ciz5BLX9OmTXPO+KzvxIkTzpn/fdG4ixEjRjhnfD6nYcOGOWf27NnjnLnjjjucM5KUmprqnNm0aZNz5osvvnDO+Gpra+u2bV0LZscBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwEwq6c9LjNYjFYopEItbLQA/Sv7/7nN3W1tYErOTSDh8+7Jy54YYbnDODBw92zhw/ftw5I/kNjY3FYs4Zn32Xl5fnnKmurnbOSNITTzzhlXPV04f0+mpoaLjqccuZEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADAjPt4YqCbtbW1ddu2pk6d6pwZNmyYc2b//v3OmSFDhjhnfKZ1S9KJEyecM5mZmc6ZaDTqnLn55pudM5999plzBt2DMyEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmGGCKHi8Igm7b1pNPPumc6dfP/Xe5lJQU58xXX33lnDlz5oxzRpJaW1udM6mpqc4Z3/W5+uMf/+iVW7FihXNm8eLFzhmfYzwUCjlnfLeVSJwJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMMMAU3Qrn8GdbW1tCVjJpc2cOdM5c+zYMedMXl6ec2bgwIHOGZ+hopLU0tLilXP1jW98o1u28/vf/94r5zPI9a233nLOPPjgg86ZnjaI1BdnQgAAM5QQAMCMcwnt2LFDs2bNUm5urkKhkDZv3tzp9iAIVFZWptzcXKWnp2vatGnav39/vNYLAOhFnEuoqalJY8aM0erVqy95+/Lly7Vy5UqtXr1a1dXVys7O1syZM9XY2Pi1FwsA6F2cn5hQUlKikpKSS94WBIFWrVqlpUuXavbs2ZKkdevWKSsrSxs2bNAzzzzz9VYLAOhV4vqYUE1NjaLRqIqLizuuC4fDuueee7Rz585LZpqbmxWLxTpdAAB9Q1xLKBqNSpKysrI6XZ+VldVx28XKy8sViUQ6Lvn5+fFcEgCgB0vIs+NCoVCnj4Mg6HLdBUuWLFFDQ0PHpba2NhFLAgD0QHF9sWp2drak82dEOTk5HdfX19d3OTu6IBwOKxwOx3MZAIAkEdczocLCQmVnZ6uioqLjupaWFlVVVWnKlCnx3BQAoBdwPhM6deqUDh482PFxTU2NPv74Yw0ZMkTDhw/XokWLtGzZMo0cOVIjR47UsmXLNHDgQD3xxBNxXTgAIPk5l9BHH32k6dOnd3xcWloqSZo7d65effVVvfDCCzpz5oyee+45nThxQhMnTtS7776rjIyM+K0aANArhIIeNgUvFospEolYLwMJ0q+f+1+A29vbnTPf+ta3nDOS9MknnzhnDh065JwZPHiwc8ZHfX29V+6mm25yznz55ZfOGZ+XZNxxxx3OmSNHjjhnJOk73/mOc8bnyVWXe+JWsmtoaLjqsc7sOACAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAmbi+sypwNT4TsX0UFxd75c6dO+ecaWlpcc6cPXvWOdO/v/u3q+9bqPi823FdXZ1zZtiwYc4Zn6/R8OHDnTOS9Itf/MIr5+rVV191zsybNy/u67DAmRAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzoSAIAutF/K9YLKZIJGK9DFyDlJQU50xbW5tzxmeY5oEDB5wzkhSNRp0zt9xyi3MmLS3NOeMzKDUWizlnJCkvL885s3nzZufMnXfe6ZzJyspyzjQ1NTlnJGnw4MHOmS+++MJrW64WLFjglfvzn/8c55VcXkNDw1X3IWdCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzPS3XgCSl88wUh8/+9nPnDP5+fle2zp58qRz5siRI86ZW2+91TmTmprqnDl16pRzpju1t7c7Z/r1c//d2Wc7knT69GnnjM9w2ubmZudMSUmJc0aSMjIynDOvv/6617auBWdCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzDDAFF4DISX/oZCu5s2b55w5ceKE17by8vKcM42Njc6ZvXv3OmdGjhzpnLnhhhucM5J0+PBh58ygQYOcMy0tLc4ZH0EQeOUGDhzonPEZGvvXv/7VOTN//nznTE/EmRAAwAwlBAAw41xCO3bs0KxZs5Sbm6tQKKTNmzd3un3evHkKhUKdLpMmTYrXegEAvYhzCTU1NWnMmDFavXr1Ze9z3333qa6uruOydevWr7VIAEDv5PzEhJKSkqu+o184HFZ2drb3ogAAfUNCHhOqrKxUZmamRo0apaefflr19fWXvW9zc7NisVinCwCgb4h7CZWUlOi1117T9u3btWLFClVXV2vGjBmXfQ/18vJyRSKRjkt+fn68lwQA6KHi/jqhOXPmdPy7qKhI48ePV0FBgbZs2aLZs2d3uf+SJUtUWlra8XEsFqOIAKCPSPiLVXNyclRQUKADBw5c8vZwOKxwOJzoZQAAeqCEv07o+PHjqq2tVU5OTqI3BQBIMs5nQqdOndLBgwc7Pq6pqdHHH3+sIUOGaMiQISorK9MjjzyinJwcHT58WD/96U81dOhQPfzww3FdOAAg+TmX0EcffaTp06d3fHzh8Zy5c+dqzZo12rdvn9avX6+TJ08qJydH06dP18aNG5WRkRG/VQMAegXnEpo2bdoVhwFu27btay0I/y8UCjlnfAY1dtcgUkmaNWuWc8ZnqOjJkyedM5KUnp7unBk8eLBzxmfY5yeffOKcSUtLc85IUkFBgXMmJSXFOePzdfI5Xtva2pwzvg4dOuSceeqppxKwkuTA7DgAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgJlQ4DN2OYFisZgikYj1MpAge/bscc5cf/31zpnLvZPv1fi8tfyAAQOcMzfeeKNzxse//vUvr5zPlG+fN670mW599uzZbtmOJK+fRR9//LFz5o477nDO+Oqu6fyS1NDQcNUp85wJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMNPfegGIr3793H+vaG9v99rW+PHjnTNjxoxxzhw7dsw5M2HCBOeMJJ04ccI5U1NT45w5ePCgcyYjI8M5M3bsWOeMJDU2Njpn/va3vzlnJk2a5JwJh8POGZ/PR/L73mhoaPDaVnfpYTOrORMCANihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghgGmHnyGhHbXYFHfYaQ+li9f7pxpbm52zvgMXDx79qxzRpLy8vKcMzfeeKNzxmc/fP75586ZTz/91DkjSVlZWc6ZgoIC58w///lP58wtt9zinPH9vjh37pxzxmcIbl/GmRAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzvWaAaSgUcs6kpqZ6baulpcU5052DRV39+Mc/9spNnDjROVNVVeWcmTJlinOmtbXVOSNJDQ0NzpmUlBTnjM+xl5OT45zJzMx0zvh66qmnnDOTJk1yznz72992zjQ2NjpnJKl/f/cfkf/973+9ttVXcSYEADBDCQEAzDiVUHl5uSZMmKCMjAxlZmbqoYce6vIeJ0EQqKysTLm5uUpPT9e0adO0f//+uC4aANA7OJVQVVWV5s+fr127dqmiokKtra0qLi5WU1NTx32WL1+ulStXavXq1aqurlZ2drZmzpzp/TdZAEDv5fSo2zvvvNPp47Vr1yozM1O7d+/W3XffrSAItGrVKi1dulSzZ8+WJK1bt05ZWVnasGGDnnnmmfitHACQ9L7WY0IXnkk0ZMgQSVJNTY2i0aiKi4s77hMOh3XPPfdo586dl/w/mpubFYvFOl0AAH2DdwkFQaDS0lJNnTpVRUVFkqRoNCqp6/vTZ2Vlddx2sfLyckUikY5Lfn6+75IAAEnGu4QWLFigvXv36vXXX+9y28Wv2QmC4LKv41myZIkaGho6LrW1tb5LAgAkGa8Xqy5cuFBvv/22duzYoby8vI7rs7OzJZ0/I/rfF9bV19d3OTu6IBwOKxwO+ywDAJDknM6EgiDQggULtGnTJm3fvl2FhYWdbi8sLFR2drYqKio6rmtpaVFVVZXXq94BAL2b05nQ/PnztWHDBr311lvKyMjoeJwnEokoPT1doVBIixYt0rJlyzRy5EiNHDlSy5Yt08CBA/XEE08k5BMAACQvpxJas2aNJGnatGmdrl+7dq3mzZsnSXrhhRd05swZPffcczpx4oQmTpyod999VxkZGXFZMACg93AqoSAIrnqfUCiksrIylZWV+a7Jy7Ws7WI+g0h9+Qy59Hmm4MKFC50zpaWlzhlJl33a/ZVceNww0dsZO3asc0aSBg0a5JzpruOoO4fgPvDAA86ZP/3pT86ZkpIS54wP333nMxjZZwiuD5+1SX4/KxOJ2XEAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADNe76zaWzz66KNeubVr1zpnfKZop6enO2d8JuT6Tv0tKipyzuzevds5M3r0aOfMwYMHnTO+2/L52p47d8454zOB/OGHH3bOSH4TsX3079+zfwT5fD8dPXo0ASvpql8/v3OItra2OK/k6+FMCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgJmePT3QQU5OjnPm5Zdf9tpWa2urc6axsdE54ztY1JXPAE5JCofDzpnJkyc7Z3bt2uWcGTFihHNG8vs6ZWZmOmcGDRrknNm0aZNzZvPmzc6Z7tTS0tIt2/H5npX8BpiePHnSa1uuQqFQt2wn0TgTAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYKbXDDB94IEHnDNDhgzx2lY0GnXODBw40DnjM1h0wIAB3bIdSWpra3PO+AxdHD9+vHPmP//5j3NGkqqrq50z48aNc87ceOONzplHHnnEOePLZzhtc3Ozc6apqck548Pn8/Hl8/OhL+NMCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgJleM8B0/fr1zpnvfe97Xtu67bbbnDMZGRnOmSAInDP9+rn/XuEziFSS2tvbnTOnT592zvgMWL3pppucM5I0bNgw58z111/vnJk+fbpzpju1trZ2y3bOnTvXo7fTv7/7j8juGsrqO3i4u76214ozIQCAGUoIAGDGqYTKy8s1YcIEZWRkKDMzUw899JA+//zzTveZN2+eQqFQp8ukSZPiumgAQO/gVEJVVVWaP3++du3apYqKCrW2tqq4uLjL30Dvu+8+1dXVdVy2bt0a10UDAHoHp0fd3nnnnU4fr127VpmZmdq9e7fuvvvujuvD4bCys7Pjs0IAQK/1tR4TamhokNT1bbIrKyuVmZmpUaNG6emnn1Z9ff1l/4/m5mbFYrFOFwBA3+BdQkEQqLS0VFOnTlVRUVHH9SUlJXrttde0fft2rVixQtXV1ZoxY8Zl33++vLxckUik45Kfn++7JABAkvF+ndCCBQu0d+9effDBB52unzNnTse/i4qKNH78eBUUFGjLli2aPXt2l/9nyZIlKi0t7fg4FotRRADQR3iV0MKFC/X2229rx44dysvLu+J9c3JyVFBQoAMHDlzy9nA4rHA47LMMAECScyqhIAi0cOFCvfnmm6qsrFRhYeFVM8ePH1dtba1ycnK8FwkA6J2cHhOaP3++/vCHP2jDhg3KyMhQNBpVNBrVmTNnJEmnTp3S888/r7///e86fPiwKisrNWvWLA0dOlQPP/xwQj4BAEDycjoTWrNmjSRp2rRpna5fu3at5s2bp5SUFO3bt0/r16/XyZMnlZOTo+nTp2vjxo1es9MAAL2b85/jriQ9PV3btm37WgsCAPQdvWaK9oU/Cbq49957vbZ1tSdjXMrcuXOdM/fff79zZuzYsc6ZtLQ050xvNWDAAOfMd7/7XedMZWWlc6Y3utwTluLNZ9K5JP373/92zuzfv99rW658p9/3NAwwBQCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYCYUXG00djeLxWKKRCLWy+hTRo0a5ZUbMWKEc+aGG25wznz11VfOGZ/Bk5J08OBBr1xvk5KS4pzproGaF7+VzLWor6/32pbPsReNRr221Rs1NDRo8ODBV7wPZ0IAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMNPfegEX62Gj7PoE35lfra2tzplz5851y3ba29udM/h/Pfn70Od48D3GOY6+nms5jnrcANMvv/xS+fn51ssAAHxNtbW1ysvLu+J9elwJtbe36+jRo8rIyFAoFOp0WywWU35+vmpra686mbU3Yz+cx344j/1wHvvhvJ6wH4IgUGNjo3Jzc9Wv35Uf9elxf47r16/fVZtz8ODBffogu4D9cB774Tz2w3nsh/Os98O1viUPT0wAAJihhAAAZpKqhMLhsF588UWFw2HrpZhiP5zHfjiP/XAe++G8ZNsPPe6JCQCAviOpzoQAAL0LJQQAMEMJAQDMUEIAADNJVUK/+tWvVFhYqAEDBmjcuHF6//33rZfUrcrKyhQKhTpdsrOzrZeVcDt27NCsWbOUm5urUCikzZs3d7o9CAKVlZUpNzdX6enpmjZtmvbv32+z2AS62n6YN29el+Nj0qRJNotNkPLyck2YMEEZGRnKzMzUQw89pM8//7zTffrC8XAt+yFZjoekKaGNGzdq0aJFWrp0qfbs2aO77rpLJSUlOnLkiPXSutXtt9+uurq6jsu+ffusl5RwTU1NGjNmjFavXn3J25cvX66VK1dq9erVqq6uVnZ2tmbOnKnGxsZuXmliXW0/SNJ9993X6fjYunVrN64w8aqqqjR//nzt2rVLFRUVam1tVXFxsZqamjru0xeOh2vZD1KSHA9BkrjzzjuDZ599ttN1t956a/CTn/zEaEXd78UXXwzGjBljvQxTkoI333yz4+P29vYgOzs7eOmllzquO3v2bBCJRIJf//rXBivsHhfvhyAIgrlz5wYPPvigyXqs1NfXB5KCqqqqIAj67vFw8X4IguQ5HpLiTKilpUW7d+9WcXFxp+uLi4u1c+dOo1XZOHDggHJzc1VYWKjHHntMhw4dsl6SqZqaGkWj0U7HRjgc1j333NPnjg1JqqysVGZmpkaNGqWnn35a9fX11ktKqIaGBknSkCFDJPXd4+Hi/XBBMhwPSVFCx44dU1tbm7Kysjpdn5WVpWg0arSq7jdx4kStX79e27Zt0yuvvKJoNKopU6bo+PHj1kszc+Hr39ePDUkqKSnRa6+9pu3bt2vFihWqrq7WjBkz1NzcbL20hAiCQKWlpZo6daqKiook9c3j4VL7QUqe46HHTdG+kovf2iEIgi7X9WYlJSUd/x49erQmT56sm266SevWrVNpaanhyuz19WNDkubMmdPx76KiIo0fP14FBQXasmWLZs+ebbiyxFiwYIH27t2rDz74oMttfel4uNx+SJbjISnOhIYOHaqUlJQuv8nU19d3+Y2nL7nuuus0evRoHThwwHopZi48O5Bjo6ucnBwVFBT0yuNj4cKFevvtt/Xee+91euuXvnY8XG4/XEpPPR6SooTS0tI0btw4VVRUdLq+oqJCU6ZMMVqVvebmZn322WfKycmxXoqZwsJCZWdndzo2WlpaVFVV1aePDUk6fvy4amtre9XxEQSBFixYoE2bNmn79u0qLCzsdHtfOR6uth8upcceD4ZPinDyxhtvBKmpqcHvfve74NNPPw0WLVoUXHfddcHhw4etl9ZtFi9eHFRWVgaHDh0Kdu3aFdx///1BRkZGr98HjY2NwZ49e4I9e/YEkoKVK1cGe/bsCb744osgCILgpZdeCiKRSLBp06Zg3759weOPPx7k5OQEsVjMeOXxdaX90NjYGCxevDjYuXNnUFNTE7z33nvB5MmTg29+85u9aj/88Ic/DCKRSFBZWRnU1dV1XE6fPt1xn75wPFxtPyTT8ZA0JRQEQfDLX/4yKCgoCNLS0oKxY8d2ejpiXzBnzpwgJycnSE1NDXJzc4PZs2cH+/fvt15Wwr333nuBpC6XuXPnBkFw/mm5L774YpCdnR2Ew+Hg7rvvDvbt22e76AS40n44ffp0UFxcHAwbNixITU0Nhg8fHsydOzc4cuSI9bLj6lKfv6Rg7dq1HffpC8fD1fZDMh0PvJUDAMBMUjwmBADonSghAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJj5Pwkl2gsPJhwtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of an image from the dataset\n",
    "image_id = 11\n",
    "plt.imshow(train_dataset[image_id][0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91523ba1",
   "metadata": {},
   "source": [
    "# MLP\n",
    "You are NOT allowed to use convolutional layers in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c220489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer perceptron with configurable architecture.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_dim: int, \n",
    "                 hidden_layers: list, \n",
    "                 output_dim: int, \n",
    "                 activation: nn.Module):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(activation())\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        # No activation on output — CrossEntropyLoss expects raw logits\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten image: (batch, 1, 28, 28) -> (batch, 784)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cecaeec",
   "metadata": {},
   "source": [
    "# Model + Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb691cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYERS = [32, 32]  # List of hidden layer sizes, e.g., [256, 128, 64]\n",
    "ACTIVATION = nn.ReLU            # Try: nn.Tanh, nn.Sigmoid, nn.LeakyReLU, nn.GELU\n",
    "LEARNING_RATE = 1e-2            # Try: 1e-1, 1e-3, 5e-4\n",
    "BATCH_SIZE = 128                # Try: 64, 256   \n",
    "EPOCHS = 10\n",
    "# Are there other hyperparameters to consider?\n",
    "\n",
    "model = MLP(\n",
    "        input_dim=28*28, # Do not change, input is 28x28 images\n",
    "        hidden_layers=HIDDEN_LAYERS,\n",
    "        output_dim=len(CLASSES),\n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # Loss function for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb9287e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "119297d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:12<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.5156, Val Loss: 0.4381, Val Acc: 83.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:12<00:00, 39.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.3988, Val Loss: 0.4253, Val Acc: 84.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 46.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.3577, Val Loss: 0.4593, Val Acc: 83.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 128/469 [00:02<00:07, 47.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m     optimizer.zero_grad()  \u001b[38;5;66;03m# Clear gradients from previous step\u001b[39;00m\n\u001b[32m     13\u001b[39m     loss.backward()        \u001b[38;5;66;03m# Backpropagation: ∂L/∂θ for all parameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     optimizer.step()       \u001b[38;5;66;03m# Update: θ → θ - η * ∂L/∂θ\u001b[39;00m\n\u001b[32m     16\u001b[39m     total_loss_train += loss.item()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Logging\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    482\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    483\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    484\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    485\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m out = func(*args, **kwargs)\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/adam.py:223\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    211\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    213\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    214\u001b[39m         group,\n\u001b[32m    215\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m         state_steps,\n\u001b[32m    221\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     adam(\n\u001b[32m    224\u001b[39m         params_with_grad,\n\u001b[32m    225\u001b[39m         grads,\n\u001b[32m    226\u001b[39m         exp_avgs,\n\u001b[32m    227\u001b[39m         exp_avg_sqs,\n\u001b[32m    228\u001b[39m         max_exp_avg_sqs,\n\u001b[32m    229\u001b[39m         state_steps,\n\u001b[32m    230\u001b[39m         amsgrad=group[\u001b[33m\"\u001b[39m\u001b[33mamsgrad\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    231\u001b[39m         has_complex=has_complex,\n\u001b[32m    232\u001b[39m         beta1=beta1,\n\u001b[32m    233\u001b[39m         beta2=beta2,\n\u001b[32m    234\u001b[39m         lr=group[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    235\u001b[39m         weight_decay=group[\u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    236\u001b[39m         eps=group[\u001b[33m\"\u001b[39m\u001b[33meps\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    237\u001b[39m         maximize=group[\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    238\u001b[39m         foreach=group[\u001b[33m\"\u001b[39m\u001b[33mforeach\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    239\u001b[39m         capturable=group[\u001b[33m\"\u001b[39m\u001b[33mcapturable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    240\u001b[39m         differentiable=group[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    241\u001b[39m         fused=group[\u001b[33m\"\u001b[39m\u001b[33mfused\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    242\u001b[39m         grad_scale=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgrad_scale\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    243\u001b[39m         found_inf=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfound_inf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    244\u001b[39m     )\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/adam.py:784\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    782\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m func(\n\u001b[32m    785\u001b[39m     params,\n\u001b[32m    786\u001b[39m     grads,\n\u001b[32m    787\u001b[39m     exp_avgs,\n\u001b[32m    788\u001b[39m     exp_avg_sqs,\n\u001b[32m    789\u001b[39m     max_exp_avg_sqs,\n\u001b[32m    790\u001b[39m     state_steps,\n\u001b[32m    791\u001b[39m     amsgrad=amsgrad,\n\u001b[32m    792\u001b[39m     has_complex=has_complex,\n\u001b[32m    793\u001b[39m     beta1=beta1,\n\u001b[32m    794\u001b[39m     beta2=beta2,\n\u001b[32m    795\u001b[39m     lr=lr,\n\u001b[32m    796\u001b[39m     weight_decay=weight_decay,\n\u001b[32m    797\u001b[39m     eps=eps,\n\u001b[32m    798\u001b[39m     maximize=maximize,\n\u001b[32m    799\u001b[39m     capturable=capturable,\n\u001b[32m    800\u001b[39m     differentiable=differentiable,\n\u001b[32m    801\u001b[39m     grad_scale=grad_scale,\n\u001b[32m    802\u001b[39m     found_inf=found_inf,\n\u001b[32m    803\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/adam.py:430\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    428\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m         denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    432\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.train()  # Enable dropout, batch norm training mode, etc.\n",
    "total_loss = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss_train = 0.0\n",
    "    for data, target in tqdm(train_loader):        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        \n",
    "        # Backward pass (compute gradients)\n",
    "        optimizer.zero_grad()  # Clear gradients from previous step\n",
    "        loss.backward()        # Backpropagation: ∂L/∂θ for all parameters\n",
    "        optimizer.step()       # Update: θ → θ - η * ∂L/∂θ\n",
    "\n",
    "        total_loss_train += loss.item()\n",
    "\n",
    "    # Logging\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data_val, target_val in test_loader:\n",
    "            output_val = model(data_val)\n",
    "            total_loss += nn.CrossEntropyLoss()(output_val, target_val).item() * target_val.size(0)\n",
    "            _, predicted = torch.max(output_val, 1)\n",
    "            correct += (predicted == target_val).sum().item()\n",
    "            total += target_val.size(0)\n",
    "\n",
    "    avg_loss_train = total_loss_train / len(train_loader)\n",
    "\n",
    "    val_loss = total_loss / total\n",
    "    val_accuracy = 100.0 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {avg_loss_train:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c46b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
